{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18d7b930",
   "metadata": {},
   "source": [
    "## 初始化环境, 固定随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "413d2e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'输出路径'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import torch\n",
    "import torchvision as tv\n",
    "\n",
    "import utils\n",
    "from transformer_flow import Model\n",
    "\n",
    "\n",
    "utils.set_random_seed(100)\n",
    "notebook_output_path = pathlib.Path('runs/notebook')\n",
    "\"\"\"输出路径\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5737d764",
   "metadata": {},
   "source": [
    "## 设置超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb5c805d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n"
     ]
    }
   ],
   "source": [
    "# region 数据集元信息\n",
    "dataset = 'mnist'\n",
    "\"\"\"数据集\"\"\"\n",
    "num_classes = 10\n",
    "\"\"\"种类数\"\"\"\n",
    "img_size = 28\n",
    "\"\"\"图像大小\"\"\"\n",
    "channel_size = 1\n",
    "\"\"\"图像通道数\"\"\"\n",
    "# endregion\n",
    "\n",
    "# region 训练超参数\n",
    "# we use a small model for fast demonstration, increase the model size for better results\n",
    "patch_size = 4\n",
    "\"\"\"图片块大小\"\"\"\n",
    "channels = 128\n",
    "\"\"\"隐藏层通道数\"\"\"\n",
    "blocks = 4\n",
    "\"\"\"MetaBlock数目\"\"\"\n",
    "layers_per_block = 4\n",
    "\"\"\"每个MetaBlock的层数\"\"\"\n",
    "# try different noise levels to see its effect\n",
    "noise_std = 0.1\n",
    "\"\"\"噪声水平\"\"\"\n",
    "\n",
    "batch_size = 256\n",
    "\"\"\"批量大小\"\"\"\n",
    "lr = 2e-3\n",
    "\"\"\"学习率\"\"\"\n",
    "# increase epochs for better results\n",
    "epochs = 100\n",
    "\"\"\"训练步长\"\"\"\n",
    "sample_freq = 10\n",
    "\"\"\"采样频率\"\"\"\n",
    "# endregion\n",
    "\n",
    "# region 设备选择\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'  # if on mac\n",
    "else:\n",
    "    device = 'cpu'  # if mps not available\n",
    "print(f'using device {device}')\n",
    "# endregion\n",
    "\n",
    "# region 采样测试集\n",
    "fixed_noise = torch.randn(num_classes * 10, (img_size // patch_size)**2, channel_size * patch_size ** 2, device=device)\n",
    "\"\"\"固定噪声, 用于检验生成效果.\n",
    "\n",
    "    shape: (B, C*P*P), 其中 B = num_classes * 10\n",
    "\"\"\"\n",
    "fixed_y = torch.arange(num_classes, device=device).view(-1, 1).repeat(1, 10).flatten()\n",
    "\"\"\"固定目标标签, 用于检验生成效果.\n",
    "\n",
    "    shape: (B), 其中 B = num_classes * 10\n",
    "\"\"\"\n",
    "# endregion\n",
    "\n",
    "\n",
    "transform = tv.transforms.Compose([\n",
    "    tv.transforms.Resize((img_size, img_size)),\n",
    "    tv.transforms.ToTensor(),\n",
    "    tv.transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\"\"\"图像预处理管道\"\"\"\n",
    "data = tv.datasets.MNIST('.', transform=transform, train=True, download=True)\n",
    "\"\"\"MNIST数据集\"\"\"\n",
    "data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\"\"\"数据加载器\"\"\"\n",
    "model = Model(in_channels=channel_size, img_size=img_size, patch_size=patch_size,\n",
    "              channels=channels, num_blocks=blocks, layers_per_block=layers_per_block,\n",
    "              num_classes=num_classes).to(device)\n",
    "\"\"\"TarFlow模型\"\"\"\n",
    "optimizer = torch.optim.AdamW(model.parameters(), betas=(0.9, 0.95), lr=lr, weight_decay=1e-4)\n",
    "\"\"\"优化器\"\"\"\n",
    "lr_schedule = utils.CosineLRSchedule(optimizer, len(data_loader), epochs * len(data_loader), 1e-6, lr)\n",
    "\"\"\"学习率迭代器\"\"\"\n",
    "model_name = f'{patch_size}_{channels}_{blocks}_{layers_per_block}_{noise_std:.2f}'\n",
    "\"\"\"模型名称\"\"\"\n",
    "sample_dir = notebook_output_path / f'{dataset}_samples_{model_name}'\n",
    "\"\"\"采样输出路径\"\"\"\n",
    "ckpt_file = notebook_output_path / f'{dataset}_model_{model_name}.pth'\n",
    "\"\"\"模型检查点保存路径\"\"\"\n",
    "sample_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7e7ba3",
   "metadata": {},
   "source": [
    "## 训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da317d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 lr 0.002000 loss -0.9788\n",
      "layer norms 2.3528 2.1979 1.4153 0.9509\n",
      "epoch 1 lr 0.001999 loss -1.3905\n",
      "layer norms 1.7008 1.8958 1.3912 0.9854\n",
      "epoch 2 lr 0.001998 loss -1.4862\n",
      "layer norms 1.4503 1.5879 1.1261 0.9480\n",
      "epoch 3 lr 0.001995 loss -1.5293\n",
      "layer norms 1.3733 1.4909 1.0987 0.9519\n",
      "epoch 4 lr 0.001992 loss -1.5488\n",
      "layer norms 1.4172 1.5663 1.1787 1.0115\n",
      "epoch 5 lr 0.001987 loss -1.5611\n",
      "layer norms 1.4108 1.5871 1.2571 0.9760\n",
      "epoch 6 lr 0.001982 loss -1.5695\n",
      "layer norms 1.4366 1.6714 1.3719 1.0523\n",
      "epoch 7 lr 0.001975 loss -1.5720\n",
      "layer norms 1.4538 1.7026 1.3861 1.0639\n",
      "epoch 8 lr 0.001968 loss -1.5795\n",
      "layer norms 1.4884 1.8108 1.5291 0.9818\n",
      "epoch 9 lr 0.001960 loss -1.5806\n",
      "layer norms 1.5015 1.8684 1.6006 0.9805\n",
      "sampling complete\n",
      "epoch 10 lr 0.001950 loss -1.5774\n",
      "layer norms 1.6227 2.0732 1.7008 0.9707\n",
      "epoch 11 lr 0.001940 loss -1.5878\n",
      "layer norms 1.5969 2.0625 1.7733 0.9937\n",
      "epoch 12 lr 0.001928 loss -1.5892\n",
      "layer norms 1.6248 2.1684 1.9259 1.0145\n",
      "epoch 13 lr 0.001916 loss -1.5921\n",
      "layer norms 1.5832 2.1153 1.8795 0.9616\n",
      "epoch 14 lr 0.001903 loss -1.5936\n",
      "layer norms 1.6383 2.2641 2.0526 0.9745\n",
      "epoch 15 lr 0.001889 loss -1.5948\n",
      "layer norms 1.6421 2.3017 2.1113 0.9788\n",
      "epoch 16 lr 0.001874 loss -1.5892\n",
      "layer norms 1.7313 2.4775 2.2724 1.0092\n",
      "epoch 17 lr 0.001858 loss -1.5970\n",
      "layer norms 1.7265 2.4943 2.3124 1.0033\n",
      "epoch 18 lr 0.001841 loss -1.5990\n",
      "layer norms 1.7632 2.5945 2.4333 0.9986\n",
      "epoch 19 lr 0.001824 loss -1.5991\n",
      "layer norms 1.7811 2.6646 2.5347 1.0131\n",
      "sampling complete\n",
      "epoch 20 lr 0.001805 loss -1.6008\n",
      "layer norms 1.7693 2.6475 2.5505 0.9860\n",
      "epoch 21 lr 0.001786 loss -1.6014\n",
      "layer norms 1.7564 2.6672 2.5910 0.9934\n",
      "epoch 22 lr 0.001766 loss -1.6027\n",
      "layer norms 1.8138 2.8021 2.7152 1.0162\n",
      "epoch 23 lr 0.001745 loss -1.6035\n",
      "layer norms 1.8087 2.8321 2.7770 1.0162\n",
      "epoch 24 lr 0.001724 loss -1.6041\n",
      "layer norms 1.8478 2.9256 2.8750 1.0082\n",
      "epoch 25 lr 0.001702 loss -1.6048\n",
      "layer norms 1.8325 2.9321 2.9172 0.9839\n",
      "epoch 26 lr 0.001679 loss -1.6056\n",
      "layer norms 1.8551 3.0137 3.0210 1.0412\n",
      "epoch 27 lr 0.001655 loss -1.6063\n",
      "layer norms 1.8483 2.9915 2.9912 1.0059\n",
      "epoch 28 lr 0.001631 loss -1.6067\n",
      "layer norms 1.8655 3.0637 3.0909 1.0030\n",
      "epoch 29 lr 0.001606 loss -1.6073\n",
      "layer norms 1.8669 3.0878 3.1213 1.0050\n",
      "sampling complete\n",
      "epoch 30 lr 0.001580 loss -1.6081\n",
      "layer norms 1.8969 3.1599 3.2082 0.9983\n",
      "epoch 31 lr 0.001554 loss -1.6087\n",
      "layer norms 1.9002 3.1712 3.2396 1.0030\n",
      "epoch 32 lr 0.001527 loss -1.6091\n",
      "layer norms 1.9062 3.2138 3.3102 1.0109\n",
      "epoch 33 lr 0.001500 loss -1.6098\n",
      "layer norms 1.9143 3.2465 3.3389 0.9919\n",
      "epoch 34 lr 0.001473 loss -1.6103\n",
      "layer norms 1.9300 3.2884 3.3997 1.0000\n",
      "epoch 35 lr 0.001444 loss -1.6109\n",
      "layer norms 1.9345 3.2969 3.4064 0.9859\n",
      "epoch 36 lr 0.001416 loss -1.6114\n",
      "layer norms 1.9499 3.3773 3.5320 0.9907\n",
      "epoch 37 lr 0.001387 loss -1.6121\n",
      "layer norms 1.9459 3.3609 3.5127 0.9980\n",
      "epoch 38 lr 0.001357 loss -1.6124\n",
      "layer norms 1.9490 3.3957 3.5805 0.9816\n",
      "epoch 39 lr 0.001327 loss -1.6128\n",
      "layer norms 1.9389 3.4054 3.5861 0.9930\n",
      "sampling complete\n",
      "epoch 40 lr 0.001297 loss -1.6134\n",
      "layer norms 1.9690 3.4657 3.7053 1.0080\n",
      "epoch 41 lr 0.001267 loss -1.6136\n",
      "layer norms 1.9762 3.4892 3.7384 0.9898\n",
      "epoch 42 lr 0.001236 loss -1.6140\n",
      "layer norms 1.9832 3.5124 3.7322 1.0187\n",
      "epoch 43 lr 0.001205 loss -1.6144\n",
      "layer norms 1.9899 3.5390 3.7484 0.9892\n",
      "epoch 44 lr 0.001174 loss -1.6150\n",
      "layer norms 1.9711 3.5072 3.7606 0.9878\n",
      "epoch 45 lr 0.001143 loss -1.6155\n",
      "layer norms 1.9798 3.5635 3.8245 1.0038\n",
      "epoch 46 lr 0.001111 loss -1.6158\n",
      "layer norms 1.9809 3.5553 3.8312 1.0112\n",
      "epoch 47 lr 0.001080 loss -1.6163\n",
      "layer norms 2.0042 3.6210 3.9189 0.9961\n",
      "epoch 48 lr 0.001048 loss -1.6168\n",
      "layer norms 2.0168 3.6490 3.9181 1.0046\n",
      "epoch 49 lr 0.001016 loss -1.6172\n",
      "layer norms 2.0253 3.6850 3.9403 0.9755\n",
      "sampling complete\n",
      "epoch 50 lr 0.000985 loss -1.6177\n",
      "layer norms 2.0036 3.6450 3.9560 0.9973\n",
      "epoch 51 lr 0.000953 loss -1.6179\n",
      "layer norms 2.0439 3.7235 4.0299 1.0057\n",
      "epoch 52 lr 0.000921 loss -1.6183\n",
      "layer norms 2.0149 3.6642 3.9589 0.9842\n",
      "epoch 53 lr 0.000890 loss -1.6189\n",
      "layer norms 2.0095 3.6482 3.9822 1.0067\n",
      "epoch 54 lr 0.000858 loss -1.6189\n",
      "layer norms 2.0208 3.6883 4.0233 0.9818\n",
      "epoch 55 lr 0.000827 loss -1.6197\n",
      "layer norms 2.0120 3.6841 4.0052 0.9936\n",
      "epoch 56 lr 0.000796 loss -1.6199\n",
      "layer norms 2.0094 3.7001 4.0541 1.0076\n",
      "epoch 57 lr 0.000765 loss -1.6204\n",
      "layer norms 2.0169 3.6991 4.0424 1.0051\n",
      "epoch 58 lr 0.000734 loss -1.6205\n",
      "layer norms 2.0208 3.7260 4.1024 1.0018\n",
      "epoch 59 lr 0.000704 loss -1.6210\n",
      "layer norms 2.0235 3.7407 4.0997 0.9867\n",
      "sampling complete\n",
      "epoch 60 lr 0.000674 loss -1.6213\n",
      "layer norms 2.0052 3.7037 4.0662 0.9962\n",
      "epoch 61 lr 0.000644 loss -1.6217\n",
      "layer norms 2.0224 3.7413 4.1182 1.0060\n",
      "epoch 62 lr 0.000614 loss -1.6219\n",
      "layer norms 2.0428 3.7863 4.1548 0.9982\n",
      "epoch 63 lr 0.000585 loss -1.6224\n",
      "layer norms 1.9950 3.7079 4.0772 0.9912\n",
      "epoch 64 lr 0.000557 loss -1.6227\n",
      "layer norms 2.0242 3.7638 4.1685 1.0113\n",
      "epoch 65 lr 0.000528 loss -1.6232\n",
      "layer norms 2.0212 3.7576 4.1450 1.0012\n",
      "epoch 66 lr 0.000501 loss -1.6234\n",
      "layer norms 2.0159 3.7535 4.1260 0.9965\n",
      "epoch 67 lr 0.000474 loss -1.6238\n",
      "layer norms 2.0086 3.7302 4.1273 1.0024\n",
      "epoch 68 lr 0.000447 loss -1.6240\n",
      "layer norms 2.0189 3.7649 4.1591 0.9936\n",
      "epoch 69 lr 0.000421 loss -1.6243\n",
      "layer norms 1.9989 3.7323 4.1599 1.0059\n",
      "sampling complete\n",
      "epoch 70 lr 0.000395 loss -1.6247\n",
      "layer norms 2.0267 3.7925 4.1955 1.0051\n",
      "epoch 71 lr 0.000370 loss -1.6250\n",
      "layer norms 2.0046 3.7461 4.1365 0.9868\n",
      "epoch 72 lr 0.000346 loss -1.6253\n",
      "layer norms 2.0333 3.8063 4.2283 0.9974\n",
      "epoch 73 lr 0.000322 loss -1.6257\n",
      "layer norms 1.9925 3.7222 4.1559 0.9971\n",
      "epoch 74 lr 0.000299 loss -1.6259\n",
      "layer norms 2.0025 3.7394 4.1609 1.0052\n",
      "epoch 75 lr 0.000277 loss -1.6261\n",
      "layer norms 2.0223 3.7878 4.2008 1.0002\n",
      "epoch 76 lr 0.000256 loss -1.6264\n",
      "layer norms 2.0084 3.7507 4.1583 0.9934\n",
      "epoch 77 lr 0.000235 loss -1.6268\n",
      "layer norms 2.0139 3.7807 4.2054 1.0016\n",
      "epoch 78 lr 0.000215 loss -1.6269\n",
      "layer norms 1.9906 3.7261 4.1617 0.9934\n",
      "epoch 79 lr 0.000196 loss -1.6274\n",
      "layer norms 2.0288 3.8108 4.2302 0.9963\n",
      "sampling complete\n",
      "epoch 80 lr 0.000177 loss -1.6275\n",
      "layer norms 1.9906 3.7261 4.1559 0.9964\n",
      "epoch 81 lr 0.000160 loss -1.6279\n",
      "layer norms 1.9885 3.7282 4.1599 0.9992\n",
      "epoch 82 lr 0.000143 loss -1.6279\n",
      "layer norms 1.9899 3.7349 4.1613 0.9965\n",
      "epoch 83 lr 0.000127 loss -1.6283\n",
      "layer norms 1.9945 3.7411 4.1885 1.0066\n",
      "epoch 84 lr 0.000112 loss -1.6283\n",
      "layer norms 1.9900 3.7303 4.1684 1.0020\n",
      "epoch 85 lr 0.000098 loss -1.6289\n",
      "layer norms 1.9764 3.6970 4.1255 0.9941\n",
      "epoch 86 lr 0.000085 loss -1.6289\n",
      "layer norms 1.9904 3.7436 4.1748 0.9973\n",
      "epoch 87 lr 0.000073 loss -1.6290\n",
      "layer norms 1.9861 3.7321 4.1737 1.0023\n",
      "epoch 88 lr 0.000061 loss -1.6293\n",
      "layer norms 1.9877 3.7358 4.1600 1.0017\n",
      "epoch 89 lr 0.000051 loss -1.6293\n",
      "layer norms 1.9993 3.7510 4.1815 0.9957\n",
      "sampling complete\n",
      "epoch 90 lr 0.000041 loss -1.6295\n",
      "layer norms 2.0115 3.7838 4.2282 0.9995\n",
      "epoch 91 lr 0.000033 loss -1.6296\n",
      "layer norms 1.9822 3.7238 4.1546 1.0031\n",
      "epoch 92 lr 0.000026 loss -1.6297\n",
      "layer norms 1.9856 3.7215 4.1575 0.9980\n",
      "epoch 93 lr 0.000019 loss -1.6298\n",
      "layer norms 1.9934 3.7493 4.1833 1.0063\n",
      "epoch 94 lr 0.000014 loss -1.6299\n",
      "layer norms 1.9931 3.7351 4.1587 0.9978\n",
      "epoch 95 lr 0.000009 loss -1.6299\n",
      "layer norms 1.9674 3.6961 4.1473 1.0038\n",
      "epoch 96 lr 0.000006 loss -1.6302\n",
      "layer norms 2.0090 3.7795 4.2124 0.9967\n",
      "epoch 97 lr 0.000003 loss -1.6301\n",
      "layer norms 1.9543 3.6693 4.1146 1.0025\n",
      "epoch 98 lr 0.000002 loss -1.6302\n",
      "layer norms 1.9773 3.7097 4.1553 0.9970\n",
      "epoch 99 lr 0.000001 loss -1.6301\n",
      "layer norms 1.9770 3.7120 4.1621 0.9987\n",
      "sampling complete\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    # 初始化累计损失\n",
    "    losses = 0\n",
    "\n",
    "    for x, y in data_loader:  # x.shape = (B, C, H, W), y.shape = (B)\n",
    "\n",
    "        x: torch.Tensor = x.to(device)\n",
    "        # 加噪声\n",
    "        eps = noise_std * torch.randn_like(x)\n",
    "        x = x + eps\n",
    "        y: torch.Tensor = y.to(device)\n",
    "\n",
    "        # 重置梯度\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向传播\n",
    "        z, outputs, logdets = model(x, y)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = model.get_loss(z, logdets)\n",
    "\n",
    "        # 计算梯度\n",
    "        loss.backward()\n",
    "\n",
    "        # 参数优化\n",
    "        optimizer.step()\n",
    "\n",
    "        # 更新学习率\n",
    "        lr_schedule.step()\n",
    "\n",
    "        # 统计损失\n",
    "        losses += loss.item()\n",
    "\n",
    "    # 打印训练信息\n",
    "    print(f\"epoch {epoch} lr {optimizer.param_groups[0]['lr']:.6f} loss {losses / len(data_loader):.4f}\")\n",
    "    print('layer norms', ' '.join([f'{z.pow(2).mean():.4f}' for z in outputs]))\n",
    "\n",
    "    # 定期逆向传播, 检查模型效果\n",
    "    if (epoch + 1) % sample_freq == 0:\n",
    "        with torch.no_grad():\n",
    "            samples = model.reverse(fixed_noise, fixed_y)\n",
    "        tv.utils.save_image(samples, sample_dir / f'samples_{epoch:03d}.png', normalize=True, nrow=10)\n",
    "        tv.utils.save_image(model.unpatchify(z[:100]), sample_dir / f'latent_{epoch:03d}.png', normalize=True, nrow=10)\n",
    "        print('sampling complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9ac2cd",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dce548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), ckpt_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977bedc3",
   "metadata": {},
   "source": [
    "## 检查模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd3fcf68-b9e5-4840-a26e-5091a16e98c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy %98.36\n"
     ]
    }
   ],
   "source": [
    "# now we can also evaluate the model by turning it into a classifier with Bayes rule, p(y|x) = p(y)p(x|y)/p(x)\n",
    "data = tv.datasets.MNIST('.', transform=transform, train=False, download=False)\n",
    "data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "num_correct = 0\n",
    "num_examples = 0\n",
    "for x, y in data_loader:  # x.shape = (B, C, W, W), y.shape = (B)\n",
    "\n",
    "    x: torch.Tensor = x.to(device)\n",
    "    y: torch.Tensor = y.to(device)\n",
    "    eps = noise_std * torch.randn_like(x)\n",
    "\n",
    "    x = x.repeat(num_classes, 1, 1, 1)  # (num_classes * B, C, W, W)\n",
    "    y_ = torch.arange(num_classes, device=device).view(-1, 1).repeat(1, y.size(0)).flatten()\n",
    "    # arange  -> (n)\n",
    "    # view    -> (n,1)\n",
    "    # repeat  -> (n,B)\n",
    "    # flatten -> (n*B)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        z, outputs, logdets = model(x, y_)\n",
    "        losses = 0.5 * z.pow(2).mean(dim=[1, 2]) - logdets  # keep the batch dimension\n",
    "        pred = losses.reshape(num_classes, y.size(0)).argmin(dim=0)\n",
    "\n",
    "    num_correct += (pred == y).sum()\n",
    "    num_examples += y.size(0)\n",
    "\n",
    "print(f'Accuracy %{100 * num_correct / num_examples:.2f}')\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
